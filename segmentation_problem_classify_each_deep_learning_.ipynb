{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqntGFxuVlUVLB0tQ/b6JD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NimraAslamkhan/segmentation-problem-classify-each-deep-learning-/blob/main/segmentation_problem_classify_each_deep_learning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1**:\n",
        " **Set Up the** **Dataset**\n",
        "\n",
        "The dataset contains the following directories and files\n",
        "\n",
        "**class_dict_seg.csv:**\n",
        "\n",
        "This likely contains information about the classes in the segmentation task.\n",
        "\n",
        "**pixel_based_mask:**\n",
        "\n",
        "Contains pixel-based masks.\n",
        "\n",
        "**test_image:**\n",
        "\n",
        "Contains test images.\n",
        "\n",
        "**test_mask:**\n",
        "\n",
        "Contains test masks.\n",
        "\n",
        "**train_image:**\n",
        "\n",
        "Contains training images.\n",
        "\n",
        "**train_mask:**\n",
        "\n",
        "Contains training masks.\n",
        "\n",
        "proceed by setting up a tensorflow dataset and data loader to use this data for training and testing. Then will integrate the partial cross entropy loss function and train a U-Net model on this dataset."
      ],
      "metadata": {
        "id": "-4N7YXxzg2-g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "L0XScHFcNGpJ",
        "outputId": "b91b9ee8-ff62-4423-ad99-89b7ee7b4e68"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-25dae098-9fbe-468c-9a82-3ffe4f58ec0a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-25dae098-9fbe-468c-9a82-3ffe4f58ec0a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving archive (9).zip to archive (9) (1).zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Preprocess  Data**\n"
      ],
      "metadata": {
        "id": "VyZEcj1kidoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "f7gf2QvTPhIr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly sample the DataFrame\n",
        "sampled_df = df.sample(frac=sample_fraction, random_state=42)\n"
      ],
      "metadata": {
        "id": "g519V8G0Qncu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original data size: {len(df)}\")\n",
        "print(f\"Sampled data size: {len(sampled_df)}\")\n",
        "print(sampled_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FE-KlSpQs5P",
        "outputId": "653041d2-4eeb-465d-f8e3-4cdab457a001"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data size: 1000\n",
            "Sampled data size: 100\n",
            "            x         y  pixel_based_mask\n",
            "521  0.184823  0.231353                 0\n",
            "737  0.668804  0.850834                 1\n",
            "740  0.846616  0.941640                 0\n",
            "660  0.407528  0.489112                 1\n",
            "411  0.701646  0.857795                 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:**\n",
        "\n",
        "**Task 1:  Implement partial Cross entropy loss bY using tensorflow**\n",
        "\n",
        "create a custom loss function that combines binary cross-entropy with a Dice coefficient loss, which is commonly used for segmentation tasks to handle class imbalance."
      ],
      "metadata": {
        "id": "ooShaUmRjKzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Partial Cross-Entropy Loss\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def partial_cross_entropy(y_true, y_pred, class_weights, epsilon=1e-7):\n",
        "    # Compute cross-entropy for each class\n",
        "    cross_entropy = - y_true * K.log(y_pred + epsilon) - (1 - y_true) * K.log(1 - y_pred + epsilon)\n",
        "\n",
        "    # Apply class weights\n",
        "    weighted_cross_entropy = class_weights * cross_entropy\n",
        "\n",
        "    # Average the loss across all classes and pixels\n",
        "    return K.mean(weighted_cross_entropy)"
      ],
      "metadata": {
        "id": "NfdWzOTMR_B_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2 : Build Your Segmentation Model**\n",
        "\n",
        "Use a standard segmentation model such as U-Net or a custom architecture."
      ],
      "metadata": {
        "id": "kd7zBMzrjzM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def unet_model(input_size=(256, 256, 3), num_classes=1):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    # Bottleneck\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "\n",
        "    # Decoder\n",
        "    u4 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3)\n",
        "    u4 = concatenate([u4, c2])\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(u4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
        "\n",
        "    u5 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
        "    u5 = concatenate([u5, c1])\n",
        "    c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(u5)\n",
        "    c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(c5)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = unet_model(input_size=(256, 256, 3), num_classes=1)\n",
        "\n",
        "# Compile the model with custom loss function\n",
        "class_weights = [1.0]  # Example: Adjust weights based on your classes\n",
        "model.compile(optimizer='adam', loss=lambda y_true, y_pred: partial_cross_entropy(y_true, y_pred, class_weights))\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS8M0iEoSKtM",
        "outputId": "7dc6ee31-2374-4797-9669-fccfd9ade14a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 256, 256, 64)         1792      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['conv2d_1[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['conv2d_3[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 128, 128, 128)        131200    ['conv2d_5[0][0]']            \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 128, 128, 256)        0         ['conv2d_transpose[0][0]',    \n",
            "                                                                     'conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 128, 128, 128)        295040    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 128, 128, 128)        147584    ['conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 256, 256, 64)         32832     ['conv2d_7[0][0]']            \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 256, 256, 128)        0         ['conv2d_transpose_1[0][0]',  \n",
            " )                                                                   'conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 256, 256, 64)         73792     ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 256, 256, 64)         36928     ['conv2d_8[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 256, 256, 1)          65        ['conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1862849 (7.11 MB)\n",
            "Trainable params: 1862849 (7.11 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the trained model\n",
        "model.save('final_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXe4tybpTbsa",
        "outputId": "cd23909a-dbac-4eca-8c25-7e5d1e0d6d47"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I proceed by setting up a PyTorch , dataset and data loader to use this data for training and testing. Then, we will integrate the partial cross entropy loss function and train a U-Net model on this dataset.**"
      ],
      "metadata": {
        "id": "D9M7yoILkmm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "1YlAKn93ctYU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset and dataloader\n",
        "train_dataset = RemoteSensingDataset(\n",
        "    image_dir=os.path.join(\"/content/extracted_images\", 'train_image'),\n",
        "    mask_dir=os.path.join(\"/content/extracted_images\", 'train_mask'),\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Example of accessing the dataset\n",
        "example_image, example_mask = next(iter(train_loader))\n",
        "example_image.shape, example_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0JeKMJ5c6xD",
        "outputId": "ce1bf372-f0f9-4168-ee83-2ca0207fe82a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 3, 420, 420]), torch.Size([4, 1, 420, 420]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Implement Partial Cross Entropy Loss**"
      ],
      "metadata": {
        "id": "lDEY8wnDk07C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class PartialCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PartialCrossEntropyLoss, self).__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        log_prob = F.log_softmax(input, dim=1)\n",
        "        loss = -torch.sum(target * log_prob) / input.size(0)\n",
        "        return loss\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kbiqf52xdLRb"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Define the U-Net Model**\n",
        "\n",
        "already defined the U-Net model earlier by using tensorflow  . Here is a recap with  **pytorch**"
      ],
      "metadata": {
        "id": "GNVcXJaZk5rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        self.enc1 = self.conv_block(3, 64)\n",
        "        self.enc2 = self.conv_block(64, 128)\n",
        "        self.enc3 = self.conv_block(128, 256)\n",
        "        self.enc4 = self.conv_block(256, 512)\n",
        "        self.center = self.conv_block(512, 1024)\n",
        "        self.dec4 = self.conv_block(1024 + 512, 512)\n",
        "        self.dec3 = self.conv_block(512 + 256, 256)\n",
        "        self.dec2 = self.conv_block(256 + 128, 128)\n",
        "        self.dec1 = self.conv_block(128 + 64, 64)\n",
        "        self.final = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    def conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def crop(self, enc, dec):\n",
        "        enc_size = enc.size()[2:]\n",
        "        dec_size = dec.size()[2:]\n",
        "        delta_h = enc_size[0] - dec_size[0]\n",
        "        delta_w = enc_size[1] - dec_size[1]\n",
        "        dec = F.pad(dec, (delta_w // 2, delta_w - delta_w // 2, delta_h // 2, delta_h - delta_h // 2))\n",
        "        return dec\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(F.max_pool2d(enc1, 2))\n",
        "        enc3 = self.enc3(F.max_pool2d(enc2, 2))\n",
        "        enc4 = self.enc4(F.max_pool2d(enc3, 2))\n",
        "        center = self.center(F.max_pool2d(enc4, 2))\n",
        "\n",
        "        dec4 = self.crop(enc4, F.interpolate(center, scale_factor=2, mode='bilinear', align_corners=True))\n",
        "        dec4 = self.dec4(torch.cat([dec4, enc4], dim=1))\n",
        "\n",
        "        dec3 = self.crop(enc3, F.interpolate(dec4, scale_factor=2, mode='bilinear', align_corners=True))\n",
        "        dec3 = self.dec3(torch.cat([dec3, enc3], dim=1))\n",
        "\n",
        "        dec2 = self.crop(enc2, F.interpolate(dec3, scale_factor=2, mode='bilinear', align_corners=True))\n",
        "        dec2 = self.dec2(torch.cat([dec2, enc2], dim=1))\n",
        "\n",
        "        dec1 = self.crop(enc1, F.interpolate(dec2, scale_factor=2, mode='bilinear', align_corners=True))\n",
        "        dec1 = self.dec1(torch.cat([dec1, enc1], dim=1))\n",
        "\n",
        "        final = self.final(dec1)\n",
        "        return final\n",
        "\n",
        "# Verify the model with a dummy input\n",
        "model = UNet()\n",
        "dummy_input = torch.randn(4, 3, 256, 256)\n",
        "output = model(dummy_input)\n",
        "output.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQYJzNTDdPrN",
        "outputId": "365e6dec-488d-4b6d-aaa3-319b32ecd055"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Train the Network**"
      ],
      "metadata": {
        "id": "hCqREW2JlRmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Instantiate model, loss, and optimizer\n",
        "model = UNet()\n",
        "criterion = PartialCrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLBiAqV2d8Nx",
        "outputId": "24aedaa8-df68-48d3-80f6-5ba9c22cf33a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.0\n",
            "Epoch 2/10, Loss: 0.0\n",
            "Epoch 3/10, Loss: 0.0\n",
            "Epoch 4/10, Loss: 0.0\n",
            "Epoch 5/10, Loss: 0.0\n",
            "Epoch 6/10, Loss: 0.0\n",
            "Epoch 7/10, Loss: 0.0\n",
            "Epoch 8/10, Loss: 0.0\n",
            "Epoch 9/10, Loss: 0.0\n",
            "Epoch 10/10, Loss: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Design and Run Experiments**\n",
        "\n",
        "Experiment Setup\n",
        "\n",
        "Learning Rates: Try 0.001, 0.0001, and 0.01.\n",
        "\n",
        "Batch Sizes: Try 16, 32, and 64.\n",
        "\n"
      ],
      "metadata": {
        "id": "PRsylU6TlY3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "whDYdhHfEnsF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture\n",
        "def build_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, image_channels)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "5e8DvT3YGFhR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables for recording results\n",
        "learning_rates = [0.001, 0.0001, 0.01]\n",
        "batch_sizes = [16, 32, 64]\n",
        "epochs = 10\n",
        "\n",
        "results = {}\n",
        "\n"
      ],
      "metadata": {
        "id": "zj9L2CBOJY9D"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets  # Assuming you use torchvision for datasets\n",
        "\n",
        "# Define your segmentation model (replace with your actual model architecture)\n",
        "class SegmentationModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SegmentationModel, self).__init__()\n",
        "        # Define your layers here, for example:\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 2, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define the forward pass\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.conv3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jrwytFnMPCE9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train the model\n",
        "def train_model(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(train_loader)"
      ],
      "metadata": {
        "id": "fkrOqI-ePKN9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate the model\n",
        "def evaluate_model(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(val_loader)"
      ],
      "metadata": {
        "id": "guxVPeU_PVru"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function to run the experiment\n",
        "def main():\n",
        "    # Define hyperparameters and configurations\n",
        "    learning_rates = [0.001, 0.0001, 0.01]\n",
        "    batch_sizes = [16, 32, 64]\n",
        "    num_epochs = 10\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "df-scYcLPXwr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over different learning rates and batch sizes\n",
        "for lr in learning_rates:\n",
        "        for batch_size in batch_sizes:\n",
        "            print(f\"Training with learning rate: {lr}, batch size: {batch_size}\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af7Ev2u7Qi1V",
        "outputId": "d6cd86de-dff3-4019-fae2-a61493319128"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with learning rate: 0.001, batch size: 16\n",
            "Training with learning rate: 0.001, batch size: 32\n",
            "Training with learning rate: 0.001, batch size: 64\n",
            "Training with learning rate: 0.01, batch size: 16\n",
            "Training with learning rate: 0.01, batch size: 32\n",
            "Training with learning rate: 0.01, batch size: 64\n",
            "Training with learning rate: 0.1, batch size: 16\n",
            "Training with learning rate: 0.1, batch size: 32\n",
            "Training with learning rate: 0.1, batch size: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define your image classification model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(train_loader)\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "    accuracy = total_correct / len(val_loader.dataset)\n",
        "    return total_loss / len(val_loader), accuracy\n",
        "\n",
        "# Main function to run the experiment\n",
        "def main():\n",
        "    # Define hyperparameters and configurations\n",
        "    learning_rates = [0.001, 0.0001, 0.01]\n",
        "    batch_sizes = [16, 32, 64]\n",
        "    num_epochs = 10\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Define transforms and dataset\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    val_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Iterate over different learning rates and batch sizes\n",
        "    for lr in learning_rates:\n",
        "        for batch_size in batch_sizes:\n",
        "            print(f\"Training with learning rate: {lr}, batch size: {batch_size}\")\n",
        "\n",
        "            # Initialize the model, optimizer, and criterion\n",
        "            model = SimpleCNN().to(device)\n",
        "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            # Training loop\n",
        "            for epoch in range(num_epochs):\n",
        "                train_loss = train_model(model, train_loader, optimizer, criterion, device)\n",
        "                print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "            # Evaluation on validation set\n",
        "            val_loss, val_accuracy = evaluate_model(model, val_loader, criterion, device)\n",
        "            print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQSk3Sl3RL0b",
        "outputId": "16e83b79-fafe-40f6-e185-0e7929b12dbe"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 48828150.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Training with learning rate: 0.001, batch size: 16\n",
            "Epoch [1/10], Train Loss: 1.2856\n",
            "Epoch [2/10], Train Loss: 0.9121\n",
            "Epoch [3/10], Train Loss: 0.7604\n",
            "Epoch [4/10], Train Loss: 0.6470\n",
            "Epoch [5/10], Train Loss: 0.5487\n",
            "Epoch [6/10], Train Loss: 0.4590\n",
            "Epoch [7/10], Train Loss: 0.3857\n",
            "Epoch [8/10], Train Loss: 0.3118\n",
            "Epoch [9/10], Train Loss: 0.2522\n",
            "Epoch [10/10], Train Loss: 0.2106\n",
            "Validation Loss: 1.3445, Validation Accuracy: 0.7027\n",
            "Training with learning rate: 0.001, batch size: 32\n",
            "Epoch [1/10], Train Loss: 1.2580\n",
            "Epoch [2/10], Train Loss: 0.8959\n",
            "Epoch [3/10], Train Loss: 0.7363\n",
            "Epoch [4/10], Train Loss: 0.6149\n",
            "Epoch [5/10], Train Loss: 0.5083\n",
            "Epoch [6/10], Train Loss: 0.4147\n",
            "Epoch [7/10], Train Loss: 0.3314\n",
            "Epoch [8/10], Train Loss: 0.2609\n",
            "Epoch [9/10], Train Loss: 0.2077\n",
            "Epoch [10/10], Train Loss: 0.1686\n",
            "Validation Loss: 1.3422, Validation Accuracy: 0.7103\n",
            "Training with learning rate: 0.001, batch size: 64\n",
            "Epoch [1/10], Train Loss: 1.2823\n",
            "Epoch [2/10], Train Loss: 0.9088\n",
            "Epoch [3/10], Train Loss: 0.7453\n",
            "Epoch [4/10], Train Loss: 0.6229\n",
            "Epoch [5/10], Train Loss: 0.5173\n",
            "Epoch [6/10], Train Loss: 0.4181\n",
            "Epoch [7/10], Train Loss: 0.3357\n",
            "Epoch [8/10], Train Loss: 0.2618\n",
            "Epoch [9/10], Train Loss: 0.2042\n",
            "Epoch [10/10], Train Loss: 0.1644\n",
            "Validation Loss: 1.3264, Validation Accuracy: 0.7125\n",
            "Training with learning rate: 0.0001, batch size: 16\n",
            "Epoch [1/10], Train Loss: 1.6259\n",
            "Epoch [2/10], Train Loss: 1.3127\n",
            "Epoch [3/10], Train Loss: 1.2022\n",
            "Epoch [4/10], Train Loss: 1.1232\n",
            "Epoch [5/10], Train Loss: 1.0611\n",
            "Epoch [6/10], Train Loss: 1.0080\n",
            "Epoch [7/10], Train Loss: 0.9606\n",
            "Epoch [8/10], Train Loss: 0.9211\n",
            "Epoch [9/10], Train Loss: 0.8820\n",
            "Epoch [10/10], Train Loss: 0.8476\n",
            "Validation Loss: 0.9237, Validation Accuracy: 0.6797\n",
            "Training with learning rate: 0.0001, batch size: 32\n",
            "Epoch [1/10], Train Loss: 1.6167\n",
            "Epoch [2/10], Train Loss: 1.3092\n",
            "Epoch [3/10], Train Loss: 1.2043\n",
            "Epoch [4/10], Train Loss: 1.1268\n",
            "Epoch [5/10], Train Loss: 1.0645\n",
            "Epoch [6/10], Train Loss: 1.0115\n",
            "Epoch [7/10], Train Loss: 0.9651\n",
            "Epoch [8/10], Train Loss: 0.9229\n",
            "Epoch [9/10], Train Loss: 0.8827\n",
            "Epoch [10/10], Train Loss: 0.8484\n",
            "Validation Loss: 0.9286, Validation Accuracy: 0.6780\n",
            "Training with learning rate: 0.0001, batch size: 64\n",
            "Epoch [1/10], Train Loss: 1.6362\n",
            "Epoch [2/10], Train Loss: 1.3272\n",
            "Epoch [3/10], Train Loss: 1.2093\n",
            "Epoch [4/10], Train Loss: 1.1258\n",
            "Epoch [5/10], Train Loss: 1.0561\n",
            "Epoch [6/10], Train Loss: 0.9971\n",
            "Epoch [7/10], Train Loss: 0.9477\n",
            "Epoch [8/10], Train Loss: 0.9100\n",
            "Epoch [9/10], Train Loss: 0.8744\n",
            "Epoch [10/10], Train Loss: 0.8411\n",
            "Validation Loss: 0.9355, Validation Accuracy: 0.6733\n",
            "Training with learning rate: 0.01, batch size: 16\n",
            "Epoch [1/10], Train Loss: 1.8356\n",
            "Epoch [2/10], Train Loss: 1.6308\n",
            "Epoch [3/10], Train Loss: 1.5828\n",
            "Epoch [4/10], Train Loss: 1.5498\n",
            "Epoch [5/10], Train Loss: 1.5227\n",
            "Epoch [6/10], Train Loss: 1.5045\n",
            "Epoch [7/10], Train Loss: 1.4956\n",
            "Epoch [8/10], Train Loss: 1.4753\n",
            "Epoch [9/10], Train Loss: 1.4763\n",
            "Epoch [10/10], Train Loss: 1.4638\n",
            "Validation Loss: 1.5453, Validation Accuracy: 0.4473\n",
            "Training with learning rate: 0.01, batch size: 32\n",
            "Epoch [1/10], Train Loss: 2.3087\n",
            "Epoch [2/10], Train Loss: 2.3040\n",
            "Epoch [3/10], Train Loss: 2.3040\n",
            "Epoch [4/10], Train Loss: 2.3040\n",
            "Epoch [5/10], Train Loss: 2.3042\n",
            "Epoch [6/10], Train Loss: 2.3037\n",
            "Epoch [7/10], Train Loss: 2.3037\n",
            "Epoch [8/10], Train Loss: 2.3042\n",
            "Epoch [9/10], Train Loss: 2.3039\n",
            "Epoch [10/10], Train Loss: 2.3038\n",
            "Validation Loss: 2.3037, Validation Accuracy: 0.1000\n",
            "Training with learning rate: 0.01, batch size: 64\n",
            "Epoch [1/10], Train Loss: 2.3105\n",
            "Epoch [2/10], Train Loss: 2.3040\n",
            "Epoch [3/10], Train Loss: 2.3039\n",
            "Epoch [4/10], Train Loss: 2.3041\n",
            "Epoch [5/10], Train Loss: 2.3041\n",
            "Epoch [6/10], Train Loss: 2.3040\n",
            "Epoch [7/10], Train Loss: 2.3042\n",
            "Epoch [8/10], Train Loss: 2.3038\n",
            "Epoch [9/10], Train Loss: 2.3040\n",
            "Epoch [10/10], Train Loss: 2.3041\n",
            "Validation Loss: 2.3031, Validation Accuracy: 0.1000\n"
          ]
        }
      ]
    }
  ]
}